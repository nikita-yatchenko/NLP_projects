{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "Using Amazon's reviews of mobile devices we are going to train and build a model that would classify reviews as positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep\n",
    "We are going to use a subset of data to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206920, 7)\n",
      "(82768, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71610</th>\n",
       "      <td>264323</td>\n",
       "      <td>Nokia C6 Unlocked GSM Phone with Easy E-mail S...</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>99.95</td>\n",
       "      <td>2</td>\n",
       "      <td>The phone's fine, im just disappointed when i ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148450</th>\n",
       "      <td>331118</td>\n",
       "      <td>Samsung Galaxy Note II N7100 16GB Gray-Unlocke...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.99</td>\n",
       "      <td>5</td>\n",
       "      <td>great</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51115</th>\n",
       "      <td>20512</td>\n",
       "      <td>Apple iPhone 5 32GB Factory Unlocked GSM Cell ...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>179.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Exceptional ... works perfectly.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31935</th>\n",
       "      <td>172253</td>\n",
       "      <td>CNPGD [U.S. Warranty] All-in-1 Smartwatch and ...</td>\n",
       "      <td>CNPGD</td>\n",
       "      <td>49.99</td>\n",
       "      <td>2</td>\n",
       "      <td>Bluetooth kept disconnecting. I was not happy ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107601</th>\n",
       "      <td>6654</td>\n",
       "      <td>Apple Iphone 4 - 8gb Sprint (CDMA) White, Smar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Same day I got it stopped working</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                       Product Name  \\\n",
       "71610       264323  Nokia C6 Unlocked GSM Phone with Easy E-mail S...   \n",
       "148450      331118  Samsung Galaxy Note II N7100 16GB Gray-Unlocke...   \n",
       "51115        20512  Apple iPhone 5 32GB Factory Unlocked GSM Cell ...   \n",
       "31935       172253  CNPGD [U.S. Warranty] All-in-1 Smartwatch and ...   \n",
       "107601        6654  Apple Iphone 4 - 8gb Sprint (CDMA) White, Smar...   \n",
       "\n",
       "       Brand Name   Price  Rating  \\\n",
       "71610       Nokia   99.95       2   \n",
       "148450        NaN  116.99       5   \n",
       "51115       Apple  179.99       5   \n",
       "31935       CNPGD   49.99       2   \n",
       "107601        NaN     NaN       1   \n",
       "\n",
       "                                                  Reviews  Review Votes  \n",
       "71610   The phone's fine, im just disappointed when i ...           1.0  \n",
       "148450                                              great           0.0  \n",
       "51115                    Exceptional ... works perfectly.           0.0  \n",
       "31935   Bluetooth kept disconnecting. I was not happy ...           0.0  \n",
       "107601                  Same day I got it stopped working           1.0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the data\n",
    "df = pd.read_csv('Amazon_Mobile_reviews.csv')\n",
    "print(df.shape)\n",
    "# Sample the data to speed up computation\n",
    "# Comment out this line to match with lecture\n",
    "df = df.sample(frac=0.4, random_state=10)\n",
    "print(df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Review Votes</th>\n",
       "      <th>Positively Rated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71610</th>\n",
       "      <td>264323</td>\n",
       "      <td>Nokia C6 Unlocked GSM Phone with Easy E-mail S...</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>99.95</td>\n",
       "      <td>2</td>\n",
       "      <td>The phone's fine, im just disappointed when i ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51115</th>\n",
       "      <td>20512</td>\n",
       "      <td>Apple iPhone 5 32GB Factory Unlocked GSM Cell ...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>179.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Exceptional ... works perfectly.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31935</th>\n",
       "      <td>172253</td>\n",
       "      <td>CNPGD [U.S. Warranty] All-in-1 Smartwatch and ...</td>\n",
       "      <td>CNPGD</td>\n",
       "      <td>49.99</td>\n",
       "      <td>2</td>\n",
       "      <td>Bluetooth kept disconnecting. I was not happy ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161957</th>\n",
       "      <td>270262</td>\n",
       "      <td>Nokia Lumia 820 8GB GSM 4G LTE Windows 8 Smart...</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>99.99</td>\n",
       "      <td>1</td>\n",
       "      <td>This phone was defective. Was very unhappy tha...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40717</th>\n",
       "      <td>226895</td>\n",
       "      <td>LG Google Nexus 5 Unlocked Phone D821, 16 GB, ...</td>\n",
       "      <td>LG</td>\n",
       "      <td>373.75</td>\n",
       "      <td>4</td>\n",
       "      <td>Nice phone. Worked very well while traveling o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27583</th>\n",
       "      <td>314599</td>\n",
       "      <td>Samsung Galaxy Grand Prime G531H/DS Internatio...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>189.90</td>\n",
       "      <td>5</td>\n",
       "      <td>i love it</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18837</th>\n",
       "      <td>249668</td>\n",
       "      <td>Motorola KRZR K1 Unlocked Cell Phone with 2 MP...</td>\n",
       "      <td>Motorola</td>\n",
       "      <td>83.99</td>\n",
       "      <td>1</td>\n",
       "      <td>This is not a new phone as advertised. It had ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130302</th>\n",
       "      <td>226943</td>\n",
       "      <td>LG Google Nexus 5 Unlocked Phone D821, 16 GB, ...</td>\n",
       "      <td>LG</td>\n",
       "      <td>373.75</td>\n",
       "      <td>5</td>\n",
       "      <td>Reached on time. Yet to open the package... It...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110148</th>\n",
       "      <td>135100</td>\n",
       "      <td>BLU Studio 5.0 C HD - Unlocked Cell Phones - R...</td>\n",
       "      <td>BLU</td>\n",
       "      <td>2000.00</td>\n",
       "      <td>5</td>\n",
       "      <td>Guys.......this phone is awesome for the price...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17546</th>\n",
       "      <td>150957</td>\n",
       "      <td>BLU Studio C Super Camera -Unlocked Smartphone...</td>\n",
       "      <td>BLU</td>\n",
       "      <td>99.00</td>\n",
       "      <td>2</td>\n",
       "      <td>So far the phone is great. But it is a mislead...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167014</th>\n",
       "      <td>103229</td>\n",
       "      <td>BLU Advance 4.0L Unlocked Smartphone -Global G...</td>\n",
       "      <td>BLU</td>\n",
       "      <td>149.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Ordered phone for daughter. A very nice phone.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93309</th>\n",
       "      <td>33121</td>\n",
       "      <td>Apple iPhone 5c 32GB (Yellow) - AT&amp;T</td>\n",
       "      <td>Apple</td>\n",
       "      <td>224.77</td>\n",
       "      <td>1</td>\n",
       "      <td>I was happy I got a case and a charger that wa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60210</th>\n",
       "      <td>185227</td>\n",
       "      <td>Hipipooo 4 Inch IP68 Waterproof 3G Rugged Andr...</td>\n",
       "      <td>shenzhen jinwanyi company</td>\n",
       "      <td>129.99</td>\n",
       "      <td>1</td>\n",
       "      <td>These phones are garbage. I ordered 2 at diffe...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107393</th>\n",
       "      <td>359657</td>\n",
       "      <td>Samsung Galaxy S6 32GB SM-G920i - Unlocked Whi...</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>459.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Buy it. Camera is great. Very responsive. A li...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162141</th>\n",
       "      <td>68450</td>\n",
       "      <td>Apple iPhone 6s Plus 32GB Unlocked GSM Smartph...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>769.99</td>\n",
       "      <td>5</td>\n",
       "      <td>Good sell good iPhone thankyou..........</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                       Product Name  \\\n",
       "71610       264323  Nokia C6 Unlocked GSM Phone with Easy E-mail S...   \n",
       "51115        20512  Apple iPhone 5 32GB Factory Unlocked GSM Cell ...   \n",
       "31935       172253  CNPGD [U.S. Warranty] All-in-1 Smartwatch and ...   \n",
       "161957      270262  Nokia Lumia 820 8GB GSM 4G LTE Windows 8 Smart...   \n",
       "40717       226895  LG Google Nexus 5 Unlocked Phone D821, 16 GB, ...   \n",
       "27583       314599  Samsung Galaxy Grand Prime G531H/DS Internatio...   \n",
       "18837       249668  Motorola KRZR K1 Unlocked Cell Phone with 2 MP...   \n",
       "130302      226943  LG Google Nexus 5 Unlocked Phone D821, 16 GB, ...   \n",
       "110148      135100  BLU Studio 5.0 C HD - Unlocked Cell Phones - R...   \n",
       "17546       150957  BLU Studio C Super Camera -Unlocked Smartphone...   \n",
       "167014      103229  BLU Advance 4.0L Unlocked Smartphone -Global G...   \n",
       "93309        33121               Apple iPhone 5c 32GB (Yellow) - AT&T   \n",
       "60210       185227  Hipipooo 4 Inch IP68 Waterproof 3G Rugged Andr...   \n",
       "107393      359657  Samsung Galaxy S6 32GB SM-G920i - Unlocked Whi...   \n",
       "162141       68450  Apple iPhone 6s Plus 32GB Unlocked GSM Smartph...   \n",
       "\n",
       "                       Brand Name    Price  Rating  \\\n",
       "71610                       Nokia    99.95       2   \n",
       "51115                       Apple   179.99       5   \n",
       "31935                       CNPGD    49.99       2   \n",
       "161957                      Nokia    99.99       1   \n",
       "40717                          LG   373.75       4   \n",
       "27583                     Samsung   189.90       5   \n",
       "18837                    Motorola    83.99       1   \n",
       "130302                         LG   373.75       5   \n",
       "110148                        BLU  2000.00       5   \n",
       "17546                         BLU    99.00       2   \n",
       "167014                        BLU   149.99       5   \n",
       "93309                       Apple   224.77       1   \n",
       "60210   shenzhen jinwanyi company   129.99       1   \n",
       "107393                    Samsung   459.99       5   \n",
       "162141                      Apple   769.99       5   \n",
       "\n",
       "                                                  Reviews  Review Votes  \\\n",
       "71610   The phone's fine, im just disappointed when i ...           1.0   \n",
       "51115                    Exceptional ... works perfectly.           0.0   \n",
       "31935   Bluetooth kept disconnecting. I was not happy ...           0.0   \n",
       "161957  This phone was defective. Was very unhappy tha...           0.0   \n",
       "40717   Nice phone. Worked very well while traveling o...           0.0   \n",
       "27583                                           i love it           0.0   \n",
       "18837   This is not a new phone as advertised. It had ...           1.0   \n",
       "130302  Reached on time. Yet to open the package... It...           0.0   \n",
       "110148  Guys.......this phone is awesome for the price...           0.0   \n",
       "17546   So far the phone is great. But it is a mislead...           0.0   \n",
       "167014     Ordered phone for daughter. A very nice phone.           0.0   \n",
       "93309   I was happy I got a case and a charger that wa...           0.0   \n",
       "60210   These phones are garbage. I ordered 2 at diffe...           3.0   \n",
       "107393  Buy it. Camera is great. Very responsive. A li...           0.0   \n",
       "162141           Good sell good iPhone thankyou..........           2.0   \n",
       "\n",
       "        Positively Rated  \n",
       "71610                  0  \n",
       "51115                  1  \n",
       "31935                  0  \n",
       "161957                 0  \n",
       "40717                  1  \n",
       "27583                  1  \n",
       "18837                  0  \n",
       "130302                 1  \n",
       "110148                 1  \n",
       "17546                  0  \n",
       "167014                 1  \n",
       "93309                  0  \n",
       "60210                  0  \n",
       "107393                 1  \n",
       "162141                 1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Remove any 'neutral' ratings equal to 3\n",
    "df = df[df['Rating'] != 3]\n",
    "\n",
    "# Encode 4s and 5s as 1 (rated positively)\n",
    "# Encode 1s and 2s as 0 (rated poorly)\n",
    "df['Positively Rated'] = np.where(df.Rating >= 4, 1, 0)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7473840095038162"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most ratings are positive\n",
    "df['Positively Rated'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Reviews'], \n",
    "                                                    df['Positively Rated'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train first entry:\n",
      "\n",
      " Came as advertised. No trouble connecting to the t-mobile network.\n",
      "\n",
      "\n",
      "X_train first entry's review is: 1\n",
      "\n",
      "\n",
      "X_train shape:  (46086,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train first entry:\\n\\n', X_train.iloc[0])\n",
    "print('\\n\\nX_train first entry\\'s review is:', y_train.iloc[0])\n",
    "print('\\n\\nX_train shape: ', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer\n",
    "CountVectorizer allows us to use the bag-of-wrods approach - which ignores sentence structure and only focuses on the number of times a word is present in the sentence. It converts a collection of text documents (reviews) into a matrix of token counts.\n",
    "\n",
    "We first instantiate CountVectorizer and fit to our training data. It finds all tookens (at least two characters long and separated by word boundaries), converts text to lowercase, and builds a vocabulary using these tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fit the CountVectorizer to the training data\n",
    "vect = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " 'admitir',\n",
       " 'blacklisted',\n",
       " 'comprehensible',\n",
       " 'dispel',\n",
       " 'feasible',\n",
       " 'headphonesblue',\n",
       " 'kook',\n",
       " 'msrp',\n",
       " 'phonefeb',\n",
       " 'reeboting',\n",
       " 'sii',\n",
       " 'tend',\n",
       " 'virgin']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27279"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are working with over 27,000 features\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<46086x27279 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1229266 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using transform method we transform X_train into a matrix of bag-of-words representation of X_train\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "X_train_vectorized\n",
    "# each row is a document and each column is a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nyatchen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9098377775180254\n",
      "Accuracy:  0.9379027533684827\n",
      "[[ 3330   575]\n",
      " [  379 11079]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "preds = log_reg.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now evaluate the coefficients of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['worst' 'junk' 'horrible' 'garbage' 'crashed' 'unable' 'empty' 'ui'\n",
      " 'stopped' 'poor']\n",
      "\n",
      "Largest Coefs: \n",
      "['excelente' 'excelent' 'loves' 'excellent' 'love' 'perfect' 'exelente'\n",
      " 'perfectly' 'awesome' 'amazing']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = log_reg.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfIdf\n",
    "Now let us use a different approach, Term Frequency Inverse Document Frequency. It allows us to weight documents tokens not only how often it appears in a document but also how often it appears in a corpus. High weight is given to token that are used a lot in particular document but not in a corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7871"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# min_df = allows to spec min # of docs a token needs to appear to be a par of a dictionary\n",
    "\n",
    "vect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also shrunk the feature space by a factor of 4 - let's see how well this model is going to perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nyatchen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9103901483768924\n",
      "Accuracy:  0.9399856798802317\n",
      "[[ 3320   585]\n",
      " [  337 11121]]\n"
     ]
    }
   ],
   "source": [
    "# using transform method we transform X_train into a matrix of bag-of-words representation of X_train\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "log_reg_tfidf = LogisticRegression()\n",
    "log_reg_tfidf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "preds = log_reg_tfidf.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! By reducing the number of features we not only decreased the run time to train our model, but also have improved the model's generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['not' 'disappointed' 'worst' 'return' 'horrible' 'slow' 'doesn' 'stopped'\n",
      " 'poor' 'waste']\n",
      "\n",
      "Largest Coefs: \n",
      "['great' 'love' 'excellent' 'perfect' 'amazing' 'good' 'best' 'far' 'easy'\n",
      " 'perfectly']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = log_reg_tfidf.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
    "# so the list returned is in order of largest to smallest\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what features appear most often in our tfidf matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      "['spoken' 'reactions' 'fidelity' 'bokeh' 'adreno' 'controlled'\n",
      " 'synchronization' 'candybar' 'comparisons' 'nav' 'rooms' 'damp' '480p'\n",
      " 'ultimo' 'warmth' '1920x1080' 'ingress' 'dragging' 'conversion'\n",
      " 'breakers']\n",
      "\n",
      "Largest tfidf: \n",
      "['real' 'don' 'excelent' 'windows' 'aaa' 'pin' 'genial' 'very' 'god'\n",
      " 'verygood' 'loveit' 'a1' 'it' 'done' 'recommended' 'excelente' 'tiempo'\n",
      " 'thx' 'fire' 'goo']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:20]]))\n",
    "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-21:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of features with the largest TfIdf contains words which appreared frequently in a review, but did not appear commonly across all reviews.\n",
    "\n",
    "List of features with the smallest TfIdf either commonly appeared across all reviews or only appeared rarely in very long reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Order with n-grams\n",
    "One problem is our bag-of-words models do not take structure of the sentence and word order into account. One way we can fix that is to consider n-grams. An n-gram is a sequence of length n of word features. For example, including bi-grams we will have 'is working' and 'not working'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52065"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(min_df = 5, ngram_range = (1,2)).fit(X_train)\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by adding bigrams we have increased doubled our feature space. Thus these n-grams can b very computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nyatchen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9322673644814028\n",
      "Accuracy:  0.9522228731367571\n",
      "[[ 3482   423]\n",
      " [  311 11147]]\n"
     ]
    }
   ],
   "source": [
    "log_reg_2gram = LogisticRegression()\n",
    "log_reg_2gram.fit(X_train_vectorized, y_train)\n",
    "\n",
    "preds = log_reg_2gram.predict(vect.transform(X_test))\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, preds))\n",
    "print('Accuracy: ', accuracy_score(y_test, preds))\n",
    "print(confusion_matrix(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! By adding bigrams we have improved our model even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['no good' 'junk' 'not good' 'horrible' 'worst' 'broken' 'not very' 'poor'\n",
      " 'terrible' 'garbage']\n",
      "\n",
      "Largest Coefs: \n",
      "['excellent' 'excelente' 'excelent' 'perfect' 'not bad' 'great' 'love'\n",
      " 'no problems' 'awesome' 'amazing']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = log_reg_2gram.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
